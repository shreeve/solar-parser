#!/usr/bin/env bun

# ==============================================================================
# Solar - SLR(1) Parser Generator for Rip
#
# Clean implementation influenced by Jison, but rewritten in Rip for
# readability, efficiency, and maintainability.
#
# Author: Steve Shreeve <steve.shreeve@gmail.com>
#   Date: November 7, 2025
# ==============================================================================

import * as fs from 'fs'
import * as path from 'path'
import { fileURLToPath, pathToFileURL } from 'url'

VERSION = '1.4.0'

# Token: A terminal symbol that cannot be broken down further
class Token
  constructor: (name, id) ->
    @id   = id   # unique numeric ID for this token
    @name = name # name of this token (terminal) ["NUMBER" or  "+"]

# Type: A nonterminal symbol that can be matched by one or more rules
class Type
  constructor: (name, id) ->
    @id       = id      # unique numeric ID for this type
    @name     = name    # name of this type (nonterminal) ["ForLoop" or "Splat"]
    @rules    = []      # rules that define this type
    @nullable = false   # true if one of the rules can produce no tokens (Œµ)
    @firsts   = new Set # FIRST set: tokens that can start this type
    @follows  = new Set # FOLLOW set: tokens that can follow this type

# Rule: One possible match for a type (Expr ‚Üí Expr + Term)
class Rule
  constructor: (type, symbols, id) ->
    @id         = id      # unique numeric ID for this rule
    @type       = type    # type (nonterminal) that this rule defines
    @symbols    = symbols # array of symbols to match ["Expr", "**"", "Expr"]
    @nullable   = false   # true if this rule can produce no tokens (Œµ)
    @firsts     = new Set # FIRST set: tokens that can start this rule
    @precedence = 0       # operator precedence for conflict resolution

# LR Item: A rule with a dot position and lookaheads (Expr ‚Üí Expr ‚Ä¢ + Term)
class Item
  constructor: (rule, lookaheads, dot = 0) ->
    @rule       = rule                      # the rule this item is based on
    @dot        = dot                       # position of the dot in the rule
    @id         = "#{@rule.id}:#{@dot}"     # compact unique ID
    @lookaheads = new Set(lookaheads or []) # lookahead tokens (if any)
    @nextSymbol = @rule.symbols[@dot]       # symbol after dot (if any)

# LR State: A set of items with transitions to other states
class State
  constructor: (items...) ->
    @id           = null           # state number (assigned later)
    @items        = new Set(items) # kernel and closure items
    @transitions  = new Map        # symbol ‚Üí next state
    @reductions   = new Set        # items that trigger a reduction
    @hasShifts    = false          # if this state has shift actions
    @hasConflicts = false          # has shift/reduce or reduce/reduce conflicts

# ==============================================================================
# SLR(1) Parser Generator
# ==============================================================================

class Generator
  constructor: (grammar, options = {}) ->

    # Configuration
    @options     = { ...grammar.options, ...options }
    @parseParams = grammar.parseParams
    @yy          = {}
    @indent      = '  '
    @double      = @indent.repeat 2
    @triple      = @indent.repeat 3

    # Detect grammar mode based on export structure
    @mode = grammar.bnf ? 'jison' : 'sexp'

    # Grammar structures
    @types     = {}
    @rules     = []
    @operators = {}
    @conflicts = 0
    @conflictDetails = []  # Track conflict details for debugging

    # Initialize symbol table with special symbols
    @symbolTable = new Map
    @symbolTable.set "$accept", new Type  "$accept", 0
    @symbolTable.set "$end"   , new Token "$end"   , 1
    @symbolTable.set "error"  , new Token "error"  , 2

    # Build parser
    @timing 'üí• Total time', =>
      @timing 'processGrammar'   , => @processGrammar grammar # Process grammar rules
      @timing 'buildLRAutomaton' , => @buildLRAutomaton()     # Build LR(0) automaton
      @timing 'processLookaheads', => @processLookaheads()    # Compute FIRST/FOLLOW and assign lookaheads
      @timing 'buildParseTable'  , => @buildParseTable()      # Build parse table with default actions

  # ============================================================================
  # Helper Functions
  # ============================================================================

  dedent: (s, indent) ->
    m = s.match /^[ \t]+(?=\S)/gm
    i = Math.min ...(m ? []).map (x) => x.length
    s = s.replace(///^[ \t]{#{i}}///gm, '').trim()
    s = s.replace /^/gm, indent if indent
    s

  timing: (label, fn) ->
    console.time(label)
    result = fn() if fn
    console.timeEnd(label)
    result

  # ============================================================================
  # Grammar Processing
  # ============================================================================

  processGrammar!: (grammar) ->
    @_processOperators grammar.operators if grammar.operators
    @_buildRules (grammar.grammar or grammar.bnf)
    @_augmentGrammar grammar

  _processOperators!: (ops) ->
    for precedence, i in ops
      for k in [1...precedence.length]
        @operators[precedence[k]] = {precedence: i + 1, assoc: precedence[0]}

  _buildRules: (grammar) ->
    actionGroups = {}
    ruleTable    = [0] # No entry in slot 0
    @symbolIds   = {"$accept": 0, "$end": 1, "error": 2}  # Add reserved symbols
    symbolId     = 3 # Next available symbol ID (after special symbols)

    # Add symbol to symbol table if not already present
    addSymbol = (name) =>
      return if not name or @symbolIds[name]

      # Use existing symbol or create a new one
      unless symbol = @symbolTable.get(name)
        id = symbolId++
        symbol = if grammar[name] then new Type(name, id) else new Token(name, id)
        @symbolTable.set name, symbol
      @symbolIds[name] = symbol.id

    # Process types and their rules
    for own type, rules of grammar
      addSymbol type
      @types[type] = @symbolTable.get type

      handles = if typeof rules is 'string' then rules.split(/\s*\|\s*/g) else rules[..]

      for handle in handles
        [symbols, action, precedence] = @_parseHandle handle

        # Add symbols to grammar
        addSymbol symbol for symbol in symbols

        # Process semantic actions
        if action
          action = @_processGrammarAction action, symbols
          label = 'case ' + (@rules.length + 1) + ':'
          actionGroups[action]?.push(label) or actionGroups[action] = [label]

        # Create rule
        rule = new Rule type, symbols, @rules.length + 1

        # Set precedence
        @_assignPrecedence rule, precedence

        @rules.push rule
        ruleTable.push [@symbolIds[type], if symbols[0] is '' then 0 else symbols.length]
        @types[type].rules.push rule

    # Generate parser components
    actionsCode = @_generateActionCode actionGroups
    @ruleData = ruleTable
    @_buildTokenMappings()

    parameters = "yytext, yyleng, yylineno, yy, yystate, $$, _$"
    parameters += ', ' + @parseParams.join(', ') if @parseParams?.length

    @performAction = "function anonymous(#{parameters}) {\n#{actionsCode}\n#{@indent}}"

  _parseHandle: (handle) ->
    if Array.isArray handle
      symbols = if typeof handle[0] is 'string' then handle[0].trim().split(/\s+/) else handle[0][..]
      symbols = symbols.map (e) -> e.replace(/\[[a-zA-Z_][a-zA-Z0-9_-]*\]/g, '')

      action     = handle[1] ?? 1
      precedence = handle[2]

      [symbols, action, precedence]
    else
      cleaned = handle.replace /\[[a-zA-Z_][a-zA-Z0-9_-]*\]/g, ''
      symbols = cleaned.trim().split ' '
      [symbols, null, null]

  _processGrammarAction: (action, symbols) ->
    switch @mode

      when 'sexp'
        getToken = (_, n) -> "$$[$0#{parseInt(n, 10) - symbols.length || ''}]"

        # Replace token references with calculated $$[n] references
        switch typeof action
          when 'string'
            regex = /(?<!\$)\$(-?\d+)/gm # Look for $n (capture just digits)
            regex = /(-?\d+)/g unless regex.test(action) # Or, all bare numbers
            result = action.replace(regex, getToken).trim()
          when 'number', 'undefined'
            result = getToken('', action || 1) # No action or just a number
          else
            result = 'null'

        return "return #{result};"

      when 'jison'
        switch typeof action
          when 'string'
            return @_generateClassAction(action, symbols)
          when 'undefined'
            # Default: for empty rules, return Œµ/null, otherwise $$[1]
            return if symbols.length is 0 then 'return null;' else 'return $$[1];'

    throw new Error "Invalid action type for mode #{@mode}: #{typeof action}"

  _generateClassAction: (action, symbols) ->
    # Jison mode: process string actions like "-> new Value $1"
    # Process named semantic values
    if action.match(/[$@][a-zA-Z][a-zA-Z0-9_]*/)
      count = {}
      names = {}

      for token, i in symbols
        symbols_i = token.match(/\[[a-zA-Z][a-zA-Z0-9_-]*\]/) # Like [var]
        if symbols_i
          symbols_i = symbols_i[0].slice(1, -1)
        else
          symbols_i = token

        if names[symbols_i]
          names[symbols_i + (++count[symbols_i])] = i + 1
        else
          names[symbols_i] = i + 1
          names[symbols_i + "1"] = i + 1
          count[symbols_i] = 1

      action = action
        .replace /\$([a-zA-Z][a-zA-Z0-9_]*)/g, (str, pl) -> if names[pl] then '$' + names[pl] else str # Like $var
        .replace  /@([a-zA-Z][a-zA-Z0-9_]*)/g, (str, pl) -> if names[pl] then '@' + names[pl] else str # Like @var

    # Transform $$ and positional references
    action
      .replace(/([^'"])\$\$|^\$\$/g, '$1this.$') # Like $$var
      .replace(/@[0$]/g, "this._$") # Like @var
      .replace(/\$(-?\d+)/g, (_, n) -> "$$[$0" + (parseInt(n, 10) - symbols.length || '') + "]") # Like $1
      .replace( /@(-?\d+)/g, (_, n) -> "_$[$0" +               (n - symbols.length || '') + "]") # Like @1

  _assignPrecedence!: (rule, precedence) ->
    if precedence?.prec and @operators[precedence.prec]
      rule.precedence = @operators[precedence.prec].precedence
    else if rule.precedence is 0
      # Use rightmost token's precedence
      for token in rule.symbols by -1
        if @operators[token] and not @types[token]
          rule.precedence = @operators[token].precedence
          break

  _generateActionCode: (actionGroups) ->
    actions = []

    # Add $0 variable for token position references
    actions.push @double + 'const $0 = $$.length - 1;'

    actions.push @double + 'switch (yystate) {'
    for action, labels of actionGroups
      if '\n' in action
        actions.push @triple + labels.join(' ')
        actions.push @dedent action, @triple
      else
        actions.push @triple + labels.concat(action).join(' ')
      actions.push @triple + 'break;' unless action.trimStart().startsWith('return')
    actions.push @double + '}'

    actions.join('\n')
      .replace(/YYABORT/g, 'return false')
      .replace(/YYACCEPT/g, 'return true')

  _buildTokenMappings!: ->
    @tokenNames = {}

    for own name, id of @symbolIds when id >= 2
      unless @types[name]
        @tokenNames[id] = name

  _augmentGrammar!: (grammar) ->
    throw new Error "Grammar error: no rules defined." if @rules.length is 0

    @start = grammar.start or @rules[0].type
    unless @types[@start]
      throw new Error "Grammar error: no start symbol '#{@start}' defined."

    acceptRule = new Rule "$accept", [@start, "$end"], 0
    @rules.push acceptRule
    @acceptRuleIndex = @rules.length - 1

    @types.$accept = @symbolTable.get "$accept"
    @types.$accept.rules.push acceptRule
    @types[@start].follows.add "$end"

  # ============================================================================
  # LR Automaton Construction
  # ============================================================================

  buildLRAutomaton!: ->
    acceptItem = new Item @rules[@acceptRuleIndex]
    firstState = @_closure new State(acceptItem)
    firstState.id = 0
    firstState.signature = "#{acceptItem.rule.id}.#{acceptItem.dot}"

    states = [firstState]
    stateMap = new Map # kernel signature -> state index
    stateMap.set firstState.signature, 0

    # Build automaton by exploring all transitions
    marked = 0
    while marked < states.length
      itemSet = states[marked++]

      # Single pass: group items by nextSymbol
      symbolItems = new Map
      for item from itemSet.items when item.nextSymbol and item.nextSymbol isnt '$end'
        items = symbolItems.get(item.nextSymbol)
        unless items
          items = []
          symbolItems.set(item.nextSymbol, items)
        items.push(item)

      # Process each symbol with its pre-collected items
      for [symbol, items] from symbolItems
        @_insertStateWithItems symbol, items, itemSet, states, stateMap

    @states = states

  # Compute closure of an LR item set (lookaheads assigned later using FOLLOW sets)
  _closure: (itemSet) ->
    closureSet = new State
    workingSet = new Set itemSet.items
    itemCores  = new Map # item.id -> item

    # Process all items
    while workingSet.size > 0
      newItems = new Set

      # Only process item cores we haven't yet seen
      for item from workingSet when !itemCores.has(item.id)

        # Add item to closure
        closureSet.items.add(item)
        itemCores.set(item.id, item)

        # Check item type
        {nextSymbol} = item

        if not nextSymbol
          # Reduction item
          closureSet.reductions.add(item)
          closureSet.hasConflicts = closureSet.reductions.size > 1 or closureSet.hasShifts
        else if not @types[nextSymbol]
          # Shift item (token)
          closureSet.hasShifts = true
          closureSet.hasConflicts = closureSet.reductions.size > 0
        else
          # Type - add items for all its rules
          type = @types[nextSymbol]
          for rule in type.rules
            # Create [B ‚Üí ‚Ä¢Œ≥] with empty lookaheads (will be filled by FOLLOW sets later)
            newItem = new Item rule
            newItems.add(newItem) unless itemCores.has(newItem.id)

      workingSet = newItems

    closureSet

  # Compute GOTO(state, symbol) - transitions from one state to another
  _goto: (itemSet, symbol) ->
    gotoSet = new State

    for item from itemSet.items when item.nextSymbol is symbol
      # Create advanced item (lookaheads will be set from FOLLOW sets later)
      newItem = new Item item.rule, null, item.dot + 1
      gotoSet.items.add newItem

    if gotoSet.items.size is 0 then gotoSet else @_closure gotoSet

  # Insert new state into automaton (items provided - no scanning needed)
  _insertStateWithItems!: (symbol, items, itemSet, states, stateMap) ->
    # Build kernel signature from provided items (already filtered)
    kernel = ([item.rule.id, item.dot + 1] for item in items)
    return unless kernel.length

    kernel.sort (a, b) -> (a[0] - b[0]) or (a[1] - b[1])
    kernelSig = (pid + '.' + pos for [pid, pos] in kernel).join '|'

    existing = stateMap.get kernelSig
    if existing?
      itemSet.transitions.set symbol, existing
      return

    # Kernel is new; compute closure now
    gotoSet = @_goto itemSet, symbol
    return unless gotoSet.items.size > 0

    gotoSet.signature = kernelSig
    gotoSet.id = states.length
    stateMap.set kernelSig, gotoSet.id
    itemSet.transitions.set symbol, gotoSet.id
    states.push gotoSet

  # ============================================================================
  # Lookahead Computation - SLR(1) Algorithm
  # ============================================================================

  processLookaheads!: ->
    @processLookaheads = => {} # Computes once; no-op on subsequent calls
    @_computeNullableSets()    # Œµ-derivable symbols
    @_computeFirstSets()       # First tokens
    @_computeFollowSets()      # Following tokens
    @_assignItemLookaheads()   # FOLLOW(A) ‚Üí item lookaheads

  # Determine nullable symbols (can derive Œµ)
  _computeNullableSets!: ->
    changed = true
    while changed
      changed = false

      # Mark rules nullable if all handle symbols are nullable
      for rule in @rules when not rule.nullable
        if rule.symbols.every (symbol) => @_isNullable symbol
          rule.nullable = changed = true

      # Propagate to types
      for symbol, type of @types when not @_isNullable symbol
        if type.rules.some (p) -> p.nullable
          type.nullable = changed = true

  _isNullable: (symbol) ->
    return true if symbol is ''
    return symbol.every((s) => @_isNullable s) if Array.isArray symbol
    @types[symbol]?.nullable or false

  # Compute FIRST sets (tokens that can begin derivations)
  _computeFirstSets!: ->
    changed = true
    while changed
      changed = false

      for rule in @rules
        firsts = @_computeFirst rule.symbols
        oldSize = rule.firsts.size
        rule.firsts.clear()
        firsts.forEach (item) => rule.firsts.add item
        changed = true if rule.firsts.size > oldSize

      for symbol, type of @types
        oldSize = type.firsts.size
        type.firsts.clear()
        for rule in type.rules
          rule.firsts.forEach (s) => type.firsts.add s
        changed = true if type.firsts.size > oldSize

  _computeFirst: (symbols) ->
    return new Set if symbols is ''
    return @_computeFirstOfSequence symbols if Array.isArray symbols
    return new Set([symbols]) unless @types[symbols]
    @types[symbols].firsts

  _computeFirstOfSequence: (symbols) ->
    firsts = new Set
    for symbol in symbols
      if @types[symbol]
        @types[symbol].firsts.forEach (s) => firsts.add s
      else
        firsts.add symbol
      break unless @_isNullable symbol
    firsts

  # Compute FOLLOW sets (tokens that can follow types)
  _computeFollowSets!: ->
    changed = true
    while changed
      changed = false

      for rule in @rules
        for symbol, i in rule.symbols when @types[symbol]
          oldSize = @types[symbol].follows.size

          if i is rule.symbols.length - 1
            # Symbol at end: add FOLLOW(LHS)
            @types[rule.type].follows.forEach (item) =>
              @types[symbol].follows.add item
          else
            # Add FIRST(Œ≤) where Œ≤ follows symbol
            beta = rule.symbols[i + 1..]
            firstSet = @_computeFirst beta

            firstSet.forEach (item) => @types[symbol].follows.add item

            # If Œ≤ is nullable, also add FOLLOW(LHS)
            if @_isNullable beta
              @types[rule.type].follows.forEach (item) =>
                @types[symbol].follows.add item

          changed = true if @types[symbol].follows.size > oldSize

  # Assign FOLLOW sets to reduction items
  _assignItemLookaheads!: ->
    for state in @states
      for item from state.reductions
        follows = @types[item.rule.type]?.follows
        if follows
          item.lookaheads.clear()
          item.lookaheads.add token for token from follows

  # ============================================================================
  # Parse Table Generation
  # ============================================================================

  buildParseTable!: (itemSets = @states) ->
    states = []
    {types, operators} = this
    [NONASSOC, SHIFT, REDUCE, ACCEPT] = [0, 1, 2, 3]

    for itemSet, k in itemSets
      state = states[k] = {}

      # Shift and goto actions
      for [stackSymbol, gotoState] from itemSet.transitions when @symbolIds[stackSymbol]?
        if types[stackSymbol]
          state[@symbolIds[stackSymbol]] = gotoState
        else
          state[@symbolIds[stackSymbol]] = [SHIFT, gotoState]

      # Accept action
      for item from itemSet.items when item.nextSymbol is "$end" and @symbolIds["$end"]?
        state[@symbolIds["$end"]] = [ACCEPT]

      # Reduce actions
      for item from itemSet.reductions
        for stackSymbol from item.lookaheads when @symbolIds[stackSymbol]?
          action = state[@symbolIds[stackSymbol]]
          op = operators[stackSymbol]

          if action
            # Resolve conflict
            which = if action[0] instanceof Array then action[0] else action
            solution = @_resolveConflict item.rule, op, [REDUCE, item.rule.id], which

            if solution.bydefault
              # Categorize conflict type
              isEmpty = item.rule.symbols.length is 0 or (item.rule.symbols.length is 1 and item.rule.symbols[0] is '')
              isPassthrough = item.rule.symbols.length is 1 and types[item.rule.symbols[0]]  # Single nonterminal
              hasPrecedence = op and item.rule.precedence > 0
              isReduceReduce = which[0] is REDUCE

              # Determine category
              category = 'empty-optional' if isEmpty
              category = 'passthrough' if !isEmpty and isPassthrough
              category = 'precedence' if !isEmpty and !isPassthrough and hasPrecedence
              category = 'reduce-reduce' if !isEmpty and !isPassthrough and !hasPrecedence and isReduceReduce
              category = 'ambiguous' if !isEmpty and !isPassthrough and !hasPrecedence and !isReduceReduce

              # Only count and track problematic conflicts (exclude benign ones)
              if category is 'reduce-reduce' or category is 'ambiguous'
                @conflicts++
                @conflictDetails.push {
                  state: k,
                  lookahead: stackSymbol,
                  lookaheadName: @tokenNames[@symbolIds[stackSymbol]] or stackSymbol,
                  rule: item.rule.id,
                  ruleType: item.rule.type,
                  ruleSymbols: item.rule.symbols.join(' '),
                  shift: if which[0] is SHIFT then which[1] else null,
                  reduce: item.rule.id,
                  resolution: if which[0] is SHIFT then 'shift' else 'reduce',
                  category: category
                }
            else
              action = solution.action
          else
            action = [REDUCE, item.rule.id]

          if action?.length
            state[@symbolIds[stackSymbol]] = action
          else if action is NONASSOC
            state[@symbolIds[stackSymbol]] = undefined

    @_computeDefaultActions @parseTable = states

  # Resolve conflicts using precedence and associativity
  _resolveConflict: (rule, op, reduce, shift) ->
    solution = {rule, operator: op, r: reduce, s: shift}
    [NONASSOC, SHIFT, REDUCE] = [0, 1, 2]

    if shift[0] is REDUCE
      solution.action = if shift[1] < reduce[1] then shift else reduce
      solution.bydefault = true if shift[1] isnt reduce[1]
      return solution

    if rule.precedence is 0 or not op
      solution.bydefault = true
      solution.action = shift
    else if rule.precedence < op.precedence
      solution.action = shift
    else if rule.precedence is op.precedence
      solution.action = switch op.assoc
        when "right" then shift
        when "left" then reduce
        when "nonassoc" then NONASSOC
        else shift
    else
      solution.action = reduce

    solution

  # Compute default actions for single-action states
  _computeDefaultActions!: (states) ->
    defaults = {}
    for state, k in states
      actionCount = 0
      lastAction = null

      for own action of state
        actionCount++
        lastAction = state[action]

      defaults[k] = lastAction if actionCount is 1 and lastAction[0] is 2

    @defaultActions = defaults

  # ============================================================================
  # Code Generation
  # ============================================================================

  # ES6 Generator - Ultra-clean single purpose
  generate: ->
    parserInstance = @_generateModuleCore()
    pureHint = "/*#__PURE__*/"
    """
    // ES6 Parser generated by Solar #{VERSION}

    const parserInstance = #{parserInstance}

    function createParser(yyInit = {}) {
      const p = Object.create(parserInstance);
      Object.defineProperty(p, "yy", {
        value: { ...yyInit },
        enumerable: false,
        writable: true,
        configurable: true,
      })
      return p
    }

    const parser = #{pureHint}createParser()

    export { parser }
    export const Parser = createParser
    export const parse = parser.parse.bind(parser)
    export default parser
    """

  _generateModuleCore: ->
    tableCode = @_generateTableCode @parseTable

    """{
      symbolIds: #{JSON.stringify @symbolIds},
      tokenNames: #{JSON.stringify(@tokenNames).replace /"([0-9]+)":/g, "$1:"},
      ruleData: #{JSON.stringify @ruleData},
      parseTable: #{tableCode},
      defaultActions: #{JSON.stringify(@defaultActions).replace /"([0-9]+)":/g, "$1:"},
      performAction: #{@performAction},
      #{String(@parseError).replace(/^function /, '')},
      #{String(@parse     ).replace(/^function /, '')},
      trace() {},
      yy: {},
    }"""

  _generateTableCode: (stateTable) ->
    JSON.stringify(stateTable, null, 0).replace /"([0-9]+)"(?=:)/g, "$1"

  # ============================================================================
  # Runtime Parser
  # ============================================================================

  parseError: (str, hash) ->
    if hash.recoverable
      @trace str
    else
      # Format error with line/column information
      line = (hash.line or 0) + 1  # Convert 0-based to 1-based
      col = hash.loc?.first_column or 0
      token = if hash.token then " (token: #{hash.token})" else ''
      text = if hash.text then " near '#{hash.text}'" else ''
      location = "line #{line}, column #{col}"
      message = "Parse error at #{location}#{token}#{text}: #{str}"

      error = new Error message
      error.hash = hash
      throw error

  parse: (input) ->
    [stk, val, loc] = [[0], [null], []]
    [parseTable, yytext, yylineno, yyleng, recovering] = [@parseTable, '', 0, 0, 0]
    [TERROR, EOF] = [2, 1]

    lexer = Object.create @lexer
    sharedState = {yy: {}}
    sharedState.yy[k] = v for own k, v of @yy

    lexer.setInput input, sharedState.yy
    [sharedState.yy.lexer, sharedState.yy.parser] = [lexer, this]

    lexer.yylloc = {} unless lexer.yylloc?
    yyloc = lexer.yylloc
    loc.push yyloc

    ranges = lexer.options?.ranges

    @parseError = if typeof sharedState.yy.parseError is 'function'
      sharedState.yy.parseError
    else
      Object.getPrototypeOf(this).parseError

    lex = =>
      token = lexer.lex() or EOF
      token = @symbolIds[token] or token unless typeof token is 'number'
      token

    [symbol, preErrorSymbol, state, action, r, yyval, p, len, newState, expected] =
      [null, null, null, null, null, {}, null, null, null, null]

    loop
      state = stk[stk.length - 1]
      action = @defaultActions[state] or (
        symbol = lex() if not symbol?
        parseTable[state]?[symbol]
      )

      unless action?.length and action[0]
        errStr = ''
        unless recovering
          expected = ("'#{@tokenNames[p]}'" for own p of parseTable[state] when @tokenNames[p] and p > TERROR)
        errStr = if lexer.showPosition
          "Parse error on line #{yylineno + 1}:\n#{lexer.showPosition()}\nExpecting #{expected.join(', ')}, got '#{@tokenNames[symbol] or symbol}'"
        else
          "Parse error on line #{yylineno + 1}: Unexpected #{if symbol is EOF then "end of input" else "'#{@tokenNames[symbol] or symbol}'"}"

          @parseError errStr, {
            text: lexer.match
            token: @tokenNames[symbol] or symbol
            line: lexer.yylineno
            loc: yyloc
            expected
          }
        throw new Error errStr

      throw new Error "Parse Error: multiple actions possible at state: #{state}, token: #{symbol}" if action[0] instanceof Array and action.length > 1

      switch action[0]
        when 1 # shift
          stk.push symbol, action[1]
          val.push lexer.yytext
          loc.push lexer.yylloc
          symbol = null
          unless preErrorSymbol
            [yyleng, yytext, yylineno, yyloc] = [lexer.yyleng, lexer.yytext, lexer.yylineno, lexer.yylloc]
            recovering-- if recovering > 0
          else
            [symbol, preErrorSymbol] = [preErrorSymbol, null]

        when 2 # reduce
          len = @ruleData[action[1]][1]
          yyval.$ = val[val.length - len]
          [locFirst, locLast] = [loc[loc.length - (len or 1)], loc[loc.length - 1]]
          yyval._$ = {
            first_line: locFirst.first_line, last_line: locLast.last_line
            first_column: locFirst.first_column, last_column: locLast.last_column
          }
          yyval._$.range = [locFirst.range[0], locLast.range[1]] if ranges

          r = @performAction.apply yyval, [yytext, yyleng, yylineno, sharedState.yy, action[1], val, loc]
          yyval.$ = r if r?

          if len
            stk.length -= len * 2
            val.length -= len
            loc.length -= len

          stk.push @ruleData[action[1]][0]
          val.push yyval.$
          loc.push yyval._$
          newState = parseTable[stk[stk.length - 2]][stk[stk.length - 1]]
          stk.push newState

        when 3 # accept
          return val[val.length - 1]

  trace!: (msg) -> # Debug output (no-op by default)
    console.log msg if @options?.debug

  createParser: ->
    parserInstance = @_generateModuleCore()
    moduleExpr = """
    (function(){
      const parserInstance = #{parserInstance}
      #{@moduleInclude || ''}
      class Parser { yy = {} }
      Parser.prototype = parserInstance
      parserInstance.Parser = Parser
      return new Parser()
    })()
    """
    parser = eval moduleExpr
    parser.rules = @rules
    parser.lexer = @lexer
    parser

# ==============================================================================
# Exports
# ==============================================================================

export { Generator }

export Parser = (grammar, options) ->
  generator = new Generator grammar, options
  generator.createParser()

export default Solar =
  Generator: (g, options) ->
    new Generator g, {...g.options, ...options}

  Parser: (grammar, options) ->
    generator = new Generator grammar, options
    generator.createParser()

# ==============================================================================
# CLI Interface
# ==============================================================================

# Check if running as CLI (handles symlinks from global install)
scriptPath = fileURLToPath(import.meta.url)
isRunAsScript = process.argv[1] and (
  process.argv[1] is scriptPath or
  fs.realpathSync(process.argv[1]) is scriptPath or
  fs.realpathSync(process.argv[1]) is fs.realpathSync(scriptPath)
)

if isRunAsScript
  do ->
    showVersion = ->
      console.log """

      Solar #{VERSION} - SLR(1) Parser Generator
      """

    showHelp = ->
      showVersion()
      console.log """
      Usage: solar [options] <grammar-file>

      Options:
        -h, --help              Show this help
        -v, --version           Show version
        -i, --info              Show grammar information
        -s, --sexpr             Show grammar as s-expression
        -c, --conflicts         Show conflict details (use with --info)
        -o, --output <file>     Output file (default: parser.js)

      Examples:
        solar grammar.js
        solar --info grammar.js
        solar --info --conflicts grammar.js
        solar --sexpr grammar.js
        solar -o parser.js grammar.js
      """

    showStats = (generator) ->
      tokens = Object.keys(generator.tokenNames or {}).length
      types = Object.keys(generator.types or {}).length
      rules = generator.rules?.length or 0
      states = generator.states?.length or 0
      conflicts = generator.conflicts or 0

      console.log """

      ‚è±Ô∏è Statistics:
      ‚Ä¢ Tokens: #{tokens}
      ‚Ä¢ Types: #{types}
      ‚Ä¢ Rules: #{rules}
      ‚Ä¢ States: #{states}
      ‚Ä¢ Conflicts: #{conflicts}
      """

      # Show conflict details if requested
      if options.conflicts and generator.conflictDetails?.length
        console.log "\nüîß Conflict Details (first 30):"
        for conflict, i in generator.conflictDetails.slice(0, 30)
          console.log "\n  #{i + 1}. State #{conflict.state}, lookahead '#{conflict.lookaheadName}':"
          console.log "     Rule #{conflict.rule}: #{conflict.ruleType} ‚Üí #{conflict.ruleSymbols}"
          console.log "     Resolution: #{conflict.resolution} (by default)"

    # Parse command line
    options = {help: false, version: false, info: false, sexpr: false, conflicts: false, output: 'parser.js'}
    grammarFile = null
    i = 0

    while i < process.argv.length - 2
      arg = process.argv[i + 2]
      switch arg
        when '-h', '--help'      then options.help      = true
        when '-v', '--version'   then options.version   = true
        when '-i', '--info'      then options.info      = true
        when '-s', '--sexpr'     then options.sexpr     = true
        when '-c', '--conflicts' then options.conflicts = true
        when '-o', '--output'    then options.output    = process.argv[++i + 2]
        else grammarFile = arg unless arg.startsWith('-')
      i++

    if options.help      then showHelp()    ; process.exit 0
    if options.version   then showVersion() ; process.exit 0
    if not grammarFile   then showHelp()    ; process.exit 0
    if options.conflicts then options.info = true  # --conflicts implies --info

    try
      unless fs.existsSync grammarFile
        console.error "Grammar file not found: #{grammarFile}"
        process.exit 1

      # Load grammar
      grammar = if grammarFile.endsWith('.js') or grammarFile.endsWith('.ts') or grammarFile.endsWith('.rip')
        (await import(pathToFileURL(path.resolve(grammarFile)).href)).default
      else if grammarFile.endsWith('.json')
        JSON.parse fs.readFileSync(grammarFile, 'utf8')
      else
        throw new Error "Unsupported format. Use .js, .ts, .json, or .rip (with Bun loader)"

      unless grammar
        throw new Error "Failed to load grammar"

      # Show grammar as s-expression
      if options.sexpr
        parts = ['(grammar']

        if grammar.grammar
          parts.push '  (rules'
          for [name, productions] from Object.entries(grammar.grammar)
            parts.push "    (#{name}"
            for production in productions
              [pattern, action, opts] = production
              action ?= 1  # Default to 1 if not provided
              actionStr = if typeof action is 'string' then action else JSON.stringify(action)
              optsStr = if opts then " #{JSON.stringify(opts)}" else ''
              patternStr = if pattern is '' then '""' else pattern
              parts.push "      (#{patternStr} #{actionStr}#{optsStr})"
            parts.push "    )"
          parts.push '  )'

        if grammar.operators?.length
          parts.push '  (operators'
          grammar.operators.forEach (op) ->
            parts.push "    (#{if Array.isArray(op) then op.join(' ') else op})"
          parts.push '  )'

        parts.push ')'
        console.log parts.join('\n')
        return

      # Generate parser
      generator = new Generator grammar, options

      if options.info
        showStats generator
      else
        parserCode = generator.generate()
        fs.writeFileSync options.output, parserCode
        console.log "\nParser generated: #{options.output}"

    catch error
      console.error "Error:", error.message
      process.exit 1
